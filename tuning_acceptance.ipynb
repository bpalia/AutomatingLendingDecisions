{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning of Loan Acceptance Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, all the necessary libraries are imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from category_encoders import WOEEncoder\n",
    "from sklearn.preprocessing import TargetEncoder\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "import optuna\n",
    "from optuna import Trial\n",
    "import joblib\n",
    "from helper_functions.ml_data_prep import (\n",
    "    X_y_spilt,\n",
    "    all_combinations,\n",
    "    stratified_sample,\n",
    "    FeatureDropper,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is loaded and appropriately splited. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsample training and validation if wanting to check the code\n",
    "# data_train = pd.read_pickle(\"./data/data_train_mod1.pkl\").pipe(\n",
    "#     stratified_sample, frac=0.1\n",
    "# )\n",
    "# data_val = pd.read_pickle(\"./data/data_val_mod1.pkl\").pipe(\n",
    "#     stratified_sample, frac=0.1\n",
    "# )\n",
    "data_train = pd.read_pickle(\"./data/data_train_mod1.pkl\")\n",
    "data_val = pd.read_pickle(\"./data/data_val_mod1.pkl\")\n",
    "X_train, y_train = X_y_spilt(data_train)\n",
    "X_val, y_val = X_y_spilt(data_val)\n",
    "counter = Counter(y_train)\n",
    "scale_pos_weight = counter[0] / counter[1]\n",
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necessary subfunctions for Optuna objective function defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoder = TargetEncoder | WOEEncoder | None\n",
    "drop_combinations = all_combinations([\"loan_amnt\", \"state\", \"purpose\"])\n",
    "\n",
    "\n",
    "def instantiate_column_dropper(trial: Trial) -> FeatureDropper:\n",
    "    drop_subset = trial.suggest_int(\n",
    "        \"drop_subset\", 0, len(drop_combinations) - 1\n",
    "    )\n",
    "    drop_cols = drop_combinations[drop_subset]\n",
    "    return FeatureDropper(drop_features=drop_cols)\n",
    "\n",
    "\n",
    "def instantiate_woe_encoder(trial: Trial) -> WOEEncoder:\n",
    "    params = {\n",
    "        \"sigma\": trial.suggest_float(\"sigma\", 0.001, 5),\n",
    "        \"regularization\": trial.suggest_float(\"regularization\", 0, 5),\n",
    "        \"randomized\": trial.suggest_categorical(\"randomized\", [True, False]),\n",
    "    }\n",
    "    return WOEEncoder(**params)\n",
    "\n",
    "\n",
    "def instantiate_target_encoder(trial: Trial) -> TargetEncoder:\n",
    "    return TargetEncoder(random_state=42)\n",
    "\n",
    "\n",
    "def instantiate_state_encoder(trial: Trial) -> Encoder:\n",
    "    state_encoders = trial.suggest_categorical(\n",
    "        \"state_encoders\", [\"target\", \"woe\", \"none\"]\n",
    "    )\n",
    "    if state_encoders == \"target\":\n",
    "        state_encoder = instantiate_target_encoder(trial)\n",
    "    elif state_encoders == \"woe\":\n",
    "        state_encoder = instantiate_woe_encoder(trial)\n",
    "    elif state_encoders == \"none\":\n",
    "        state_encoder = None\n",
    "    return state_encoder\n",
    "\n",
    "\n",
    "def instantiate_purpose_encoder(trial: Trial) -> Encoder:\n",
    "    purpose_encoders = trial.suggest_categorical(\n",
    "        \"purpose_encoders\", [\"target\", \"woe\", \"none\"]\n",
    "    )\n",
    "    if purpose_encoders == \"target\":\n",
    "        purpose_encoder = instantiate_target_encoder(trial)\n",
    "    elif purpose_encoders == \"woe\":\n",
    "        purpose_encoder = instantiate_woe_encoder(trial)\n",
    "    elif purpose_encoders == \"none\":\n",
    "        purpose_encoder = None\n",
    "    return purpose_encoder\n",
    "\n",
    "\n",
    "def instantiate_risk_encoder(trial: Trial) -> Encoder:\n",
    "    risk_encoders = trial.suggest_categorical(\n",
    "        \"risk_encoders\", [\"target\", \"woe\", \"none\"]\n",
    "    )\n",
    "    if risk_encoders == \"target\":\n",
    "        risk_encoder = instantiate_target_encoder(trial)\n",
    "    elif risk_encoders == \"woe\":\n",
    "        risk_encoder = instantiate_woe_encoder(trial)\n",
    "    elif risk_encoders == \"none\":\n",
    "        risk_encoder = None\n",
    "    return risk_encoder\n",
    "\n",
    "\n",
    "def instantiate_state_transformer(trial: Trial) -> Pipeline:\n",
    "    return Pipeline([(\"encoder\", instantiate_state_encoder(trial))])\n",
    "\n",
    "\n",
    "def instantiate_purpose_transformer(trial: Trial) -> Pipeline:\n",
    "    return Pipeline([(\"encoder\", instantiate_purpose_encoder(trial))])\n",
    "\n",
    "\n",
    "def instantiate_risk_transformer(trial: Trial) -> Pipeline:\n",
    "    return Pipeline([(\"encoder\", instantiate_risk_encoder(trial))])\n",
    "\n",
    "\n",
    "def instantiate_processor(trial: Trial) -> ColumnTransformer:\n",
    "    processor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\n",
    "                \"state\",\n",
    "                instantiate_state_transformer(trial),\n",
    "                make_column_selector(pattern=\"state\"),\n",
    "            ),\n",
    "            (\n",
    "                \"purpose\",\n",
    "                instantiate_purpose_transformer(trial),\n",
    "                make_column_selector(pattern=\"purpose\"),\n",
    "            ),\n",
    "            (\n",
    "                \"risk\",\n",
    "                instantiate_risk_transformer(trial),\n",
    "                make_column_selector(pattern=\"risk\"),\n",
    "            ),\n",
    "        ],\n",
    "        remainder=\"passthrough\",\n",
    "        verbose_feature_names_out=False,\n",
    "    ).set_output(transform=\"pandas\")\n",
    "    return processor\n",
    "\n",
    "\n",
    "def instantiate_xgboost(trial: Trial) -> XGBClassifier:\n",
    "    params = {\n",
    "        \"verbosity\": 0,\n",
    "        \"n_jobs\": 4,\n",
    "        \"random_state\": 42,\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"booster\": \"gbtree\",\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"grow_policy\": \"depthwise\",\n",
    "        \"eval_metric\": \"auc\",\n",
    "        \"early_stopping_rounds\": 5,\n",
    "        \"enable_categorical\": True,\n",
    "        \"max_cat_to_onehot\": 10,\n",
    "        \"scale_pos_weight\": trial.suggest_categorical(\n",
    "            \"scale_pos_weight\", [10, 20]\n",
    "        ),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 15, step=2),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.2, 0.8, step=0.1),\n",
    "        \"colsample_bytree\": trial.suggest_float(\n",
    "            \"colsample_bytree\", 0.5, 1.0, step=0.1\n",
    "        ),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 1e-4, 10, log=True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-4, 10, log=True),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-4, 10, log=True),\n",
    "    }\n",
    "\n",
    "    pruning_callback = optuna.integration.XGBoostPruningCallback(\n",
    "        trial, \"validation_0-auc\"\n",
    "    )\n",
    "    return XGBClassifier(**params, callbacks=[pruning_callback])\n",
    "\n",
    "\n",
    "def instantiate_model(trial: Trial) -> Pipeline:\n",
    "    pipeline = Pipeline(\n",
    "        [\n",
    "            (\"drop\", instantiate_column_dropper(trial)),\n",
    "            (\"processor\", instantiate_processor(trial)),\n",
    "            (\"estimator\", instantiate_xgboost(trial)),\n",
    "        ]\n",
    "    )\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optuna study defined and run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-29 00:12:36,938] A new study created in RDB with name: model1_hypertune\n",
      "[I 2024-01-29 00:13:37,440] Trial 0 finished with value: 0.9924136696992802 and parameters: {'drop_subset': 6, 'state_encoders': 'none', 'purpose_encoders': 'woe', 'sigma': 2.9164500480582007, 'regularization': 1.4676046125392395, 'randomized': False, 'risk_encoders': 'target', 'scale_pos_weight': 20, 'max_depth': 15, 'min_child_weight': 7, 'subsample': 0.6000000000000001, 'colsample_bytree': 1.0, 'gamma': 0.00046679403764890415, 'reg_lambda': 0.0023303989033038623, 'reg_alpha': 0.038352673382299564}. Best is trial 0 with value: 0.9924136696992802.\n",
      "[I 2024-01-29 00:15:07,627] Trial 1 finished with value: 0.9118056114338022 and parameters: {'drop_subset': 5, 'state_encoders': 'woe', 'sigma': 2.896953904613107, 'regularization': 4.998571232410977, 'randomized': True, 'purpose_encoders': 'woe', 'risk_encoders': 'woe', 'scale_pos_weight': 10, 'max_depth': 13, 'min_child_weight': 9, 'subsample': 0.2, 'colsample_bytree': 0.8, 'gamma': 0.041609457976573706, 'reg_lambda': 0.018456533384976197, 'reg_alpha': 0.001004651060973162}. Best is trial 0 with value: 0.9924136696992802.\n",
      "[I 2024-01-29 00:16:55,506] Trial 2 finished with value: 0.9899285792338268 and parameters: {'drop_subset': 6, 'state_encoders': 'woe', 'sigma': 4.582992880265568, 'regularization': 4.537513506626338, 'randomized': True, 'purpose_encoders': 'woe', 'risk_encoders': 'none', 'scale_pos_weight': 20, 'max_depth': 13, 'min_child_weight': 6, 'subsample': 0.6000000000000001, 'colsample_bytree': 0.6, 'gamma': 7.70022348467021, 'reg_lambda': 0.00038527613872340715, 'reg_alpha': 0.7343070675044876}. Best is trial 0 with value: 0.9924136696992802.\n",
      "[I 2024-01-29 00:17:54,619] Trial 3 finished with value: 0.9931892768289499 and parameters: {'drop_subset': 5, 'state_encoders': 'none', 'purpose_encoders': 'target', 'risk_encoders': 'woe', 'sigma': 3.203696691693105, 'regularization': 2.5850093923486117, 'randomized': False, 'scale_pos_weight': 20, 'max_depth': 15, 'min_child_weight': 9, 'subsample': 0.4, 'colsample_bytree': 0.6, 'gamma': 0.00015864240498315207, 'reg_lambda': 0.00017347945613677167, 'reg_alpha': 0.022930336547619726}. Best is trial 3 with value: 0.9931892768289499.\n",
      "[I 2024-01-29 00:19:24,521] Trial 4 finished with value: 0.9898840760438975 and parameters: {'drop_subset': 4, 'state_encoders': 'none', 'purpose_encoders': 'target', 'risk_encoders': 'target', 'scale_pos_weight': 20, 'max_depth': 7, 'min_child_weight': 8, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.6, 'gamma': 2.836579586590577, 'reg_lambda': 0.0019628057090857313, 'reg_alpha': 0.028557375561363913}. Best is trial 3 with value: 0.9931892768289499.\n",
      "[I 2024-01-29 00:20:12,026] Trial 5 finished with value: 0.9856267251162473 and parameters: {'drop_subset': 5, 'state_encoders': 'woe', 'sigma': 4.382598795179923, 'regularization': 1.0450695433311752, 'randomized': False, 'purpose_encoders': 'none', 'risk_encoders': 'none', 'scale_pos_weight': 10, 'max_depth': 7, 'min_child_weight': 8, 'subsample': 0.6000000000000001, 'colsample_bytree': 1.0, 'gamma': 0.00010798011496733377, 'reg_lambda': 0.01048644922625017, 'reg_alpha': 0.00015170655549170172}. Best is trial 3 with value: 0.9931892768289499.\n",
      "[I 2024-01-29 00:21:30,185] Trial 6 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-01-29 00:23:03,667] Trial 7 finished with value: 0.9896350663513472 and parameters: {'drop_subset': 1, 'state_encoders': 'target', 'purpose_encoders': 'none', 'risk_encoders': 'target', 'scale_pos_weight': 20, 'max_depth': 9, 'min_child_weight': 2, 'subsample': 0.2, 'colsample_bytree': 0.8, 'gamma': 0.08376397693157095, 'reg_lambda': 0.016903881638757858, 'reg_alpha': 0.8157490067626538}. Best is trial 3 with value: 0.9931892768289499.\n",
      "[I 2024-01-29 00:23:45,516] Trial 8 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-01-29 00:24:07,078] Trial 9 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-01-29 00:26:18,397] Trial 10 finished with value: 0.9907329012924817 and parameters: {'drop_subset': 1, 'state_encoders': 'target', 'purpose_encoders': 'target', 'risk_encoders': 'woe', 'sigma': 0.4713706635727126, 'regularization': 3.321170578343194, 'randomized': False, 'scale_pos_weight': 20, 'max_depth': 15, 'min_child_weight': 4, 'subsample': 0.4, 'colsample_bytree': 0.5, 'gamma': 0.0052784890761701, 'reg_lambda': 0.30176348193270913, 'reg_alpha': 5.700643937876621}. Best is trial 3 with value: 0.9931892768289499.\n",
      "[I 2024-01-29 00:27:41,295] Trial 11 finished with value: 0.9939404090521105 and parameters: {'drop_subset': 3, 'state_encoders': 'none', 'purpose_encoders': 'woe', 'sigma': 2.914089599642267, 'regularization': 2.719568902735809, 'randomized': False, 'risk_encoders': 'target', 'scale_pos_weight': 20, 'max_depth': 15, 'min_child_weight': 7, 'subsample': 0.5, 'colsample_bytree': 0.7, 'gamma': 0.0024357897524338755, 'reg_lambda': 0.00011767545971520449, 'reg_alpha': 0.014861201617206594}. Best is trial 11 with value: 0.9939404090521105.\n",
      "[I 2024-01-29 00:29:05,605] Trial 12 finished with value: 0.9939254757779119 and parameters: {'drop_subset': 3, 'state_encoders': 'none', 'purpose_encoders': 'woe', 'sigma': 2.033810726759215, 'regularization': 2.7775539030197156, 'randomized': False, 'risk_encoders': 'target', 'scale_pos_weight': 20, 'max_depth': 15, 'min_child_weight': 10, 'subsample': 0.4, 'colsample_bytree': 0.7, 'gamma': 0.004362528196139025, 'reg_lambda': 0.00011669672316516556, 'reg_alpha': 0.003570049447217506}. Best is trial 11 with value: 0.9939404090521105.\n",
      "[I 2024-01-29 00:30:29,480] Trial 13 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-01-29 00:31:44,053] Trial 14 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-01-29 00:33:07,034] Trial 15 finished with value: 0.993795567702094 and parameters: {'drop_subset': 3, 'state_encoders': 'none', 'purpose_encoders': 'woe', 'sigma': 3.7259236917773952, 'regularization': 3.9906337665932448, 'randomized': False, 'risk_encoders': 'target', 'scale_pos_weight': 20, 'max_depth': 15, 'min_child_weight': 4, 'subsample': 0.5, 'colsample_bytree': 0.7, 'gamma': 0.1546587904000038, 'reg_lambda': 0.0005302017611266437, 'reg_alpha': 0.00669637536059249}. Best is trial 11 with value: 0.9939404090521105.\n",
      "[I 2024-01-29 00:35:01,190] Trial 16 finished with value: 0.9908124580492577 and parameters: {'drop_subset': 0, 'state_encoders': 'target', 'purpose_encoders': 'woe', 'sigma': 1.0435776727458066, 'regularization': 2.072817308253286, 'randomized': False, 'risk_encoders': 'target', 'scale_pos_weight': 20, 'max_depth': 11, 'min_child_weight': 8, 'subsample': 0.7, 'colsample_bytree': 0.5, 'gamma': 0.01288461455932575, 'reg_lambda': 9.117514893938461, 'reg_alpha': 0.0008934823791586881}. Best is trial 11 with value: 0.9939404090521105.\n",
      "[I 2024-01-29 00:36:16,514] Trial 17 finished with value: 0.9940627821017751 and parameters: {'drop_subset': 2, 'state_encoders': 'none', 'purpose_encoders': 'none', 'risk_encoders': 'target', 'scale_pos_weight': 20, 'max_depth': 13, 'min_child_weight': 7, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.8, 'gamma': 0.002434199898156847, 'reg_lambda': 0.00010444813381897536, 'reg_alpha': 0.008966888522828979}. Best is trial 17 with value: 0.9940627821017751.\n",
      "[I 2024-01-29 00:37:22,160] Trial 18 finished with value: 0.9702988720066259 and parameters: {'drop_subset': 2, 'state_encoders': 'none', 'purpose_encoders': 'none', 'risk_encoders': 'target', 'scale_pos_weight': 10, 'max_depth': 9, 'min_child_weight': 7, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.9, 'gamma': 0.001342337333563709, 'reg_lambda': 0.08825288653009696, 'reg_alpha': 0.014084691725878484}. Best is trial 17 with value: 0.9940627821017751.\n",
      "[I 2024-01-29 00:38:34,330] Trial 19 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-01-29 00:39:31,657] Trial 20 finished with value: 0.9909771001805223 and parameters: {'drop_subset': 0, 'state_encoders': 'none', 'purpose_encoders': 'none', 'risk_encoders': 'none', 'scale_pos_weight': 20, 'max_depth': 7, 'min_child_weight': 5, 'subsample': 0.5, 'colsample_bytree': 0.9, 'gamma': 0.024792436692103664, 'reg_lambda': 0.00655730765751134, 'reg_alpha': 0.0006387781345099979}. Best is trial 17 with value: 0.9940627821017751.\n",
      "[I 2024-01-29 00:40:55,478] Trial 21 finished with value: 0.9938933521435931 and parameters: {'drop_subset': 3, 'state_encoders': 'none', 'purpose_encoders': 'none', 'risk_encoders': 'target', 'scale_pos_weight': 20, 'max_depth': 15, 'min_child_weight': 7, 'subsample': 0.4, 'colsample_bytree': 0.7, 'gamma': 0.0017252420937600376, 'reg_lambda': 0.0001313906262213113, 'reg_alpha': 0.0077445313952061974}. Best is trial 17 with value: 0.9940627821017751.\n",
      "[I 2024-01-29 00:42:25,328] Trial 22 finished with value: 0.9908689422952766 and parameters: {'drop_subset': 4, 'state_encoders': 'none', 'purpose_encoders': 'woe', 'sigma': 2.338476475734217, 'regularization': 2.6068604828461193, 'randomized': True, 'risk_encoders': 'target', 'scale_pos_weight': 20, 'max_depth': 13, 'min_child_weight': 9, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.8, 'gamma': 0.0030783746474968773, 'reg_lambda': 0.00036177191600480135, 'reg_alpha': 0.0021142932290250747}. Best is trial 17 with value: 0.9940627821017751.\n",
      "[I 2024-01-29 00:44:26,583] Trial 23 finished with value: 0.9905069870882807 and parameters: {'drop_subset': 1, 'state_encoders': 'none', 'purpose_encoders': 'woe', 'sigma': 3.6378080738830514, 'regularization': 0.31147470930348087, 'randomized': False, 'risk_encoders': 'target', 'scale_pos_weight': 20, 'max_depth': 15, 'min_child_weight': 1, 'subsample': 0.5, 'colsample_bytree': 0.6, 'gamma': 0.012654471163549846, 'reg_lambda': 0.00010331684031109839, 'reg_alpha': 0.011994561785933649}. Best is trial 17 with value: 0.9940627821017751.\n",
      "[I 2024-01-29 00:45:34,366] Trial 24 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-01-29 00:47:06,840] Trial 25 finished with value: 0.9906175047171728 and parameters: {'drop_subset': 4, 'state_encoders': 'none', 'purpose_encoders': 'woe', 'sigma': 0.22727039656830428, 'regularization': 3.9573785935007617, 'randomized': False, 'risk_encoders': 'target', 'scale_pos_weight': 20, 'max_depth': 13, 'min_child_weight': 6, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.8, 'gamma': 0.011306360810822022, 'reg_lambda': 0.0009641125816234035, 'reg_alpha': 0.0020700474436375657}. Best is trial 17 with value: 0.9940627821017751.\n",
      "[I 2024-01-29 00:48:30,869] Trial 26 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-01-29 00:50:00,730] Trial 27 finished with value: 0.994137699249108 and parameters: {'drop_subset': 2, 'state_encoders': 'none', 'purpose_encoders': 'woe', 'sigma': 2.2695756956414, 'regularization': 1.896902380346106, 'randomized': False, 'risk_encoders': 'target', 'scale_pos_weight': 20, 'max_depth': 13, 'min_child_weight': 7, 'subsample': 0.4, 'colsample_bytree': 0.7, 'gamma': 0.032612254393383375, 'reg_lambda': 0.004741284303250504, 'reg_alpha': 0.0003980917632392694}. Best is trial 27 with value: 0.994137699249108.\n",
      "[I 2024-01-29 00:51:24,026] Trial 28 pruned. Trial was pruned at iteration 8.\n",
      "[I 2024-01-29 00:52:39,813] Trial 29 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-01-29 00:54:21,497] Trial 30 finished with value: 0.9908276078805549 and parameters: {'drop_subset': 1, 'state_encoders': 'none', 'purpose_encoders': 'woe', 'sigma': 2.575695211071755, 'regularization': 1.2685758825155102, 'randomized': False, 'risk_encoders': 'target', 'scale_pos_weight': 20, 'max_depth': 9, 'min_child_weight': 7, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.7, 'gamma': 0.0003831324854037193, 'reg_lambda': 0.05175473245403218, 'reg_alpha': 8.046709352790433}. Best is trial 27 with value: 0.994137699249108.\n",
      "[I 2024-01-29 00:55:43,973] Trial 31 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-01-29 00:57:09,224] Trial 32 pruned. Trial was pruned at iteration 7.\n",
      "[I 2024-01-29 00:58:40,200] Trial 33 finished with value: 0.993475676458966 and parameters: {'drop_subset': 2, 'state_encoders': 'none', 'purpose_encoders': 'woe', 'sigma': 2.5320738385164976, 'regularization': 1.649866706505697, 'randomized': False, 'risk_encoders': 'target', 'scale_pos_weight': 20, 'max_depth': 15, 'min_child_weight': 6, 'subsample': 0.2, 'colsample_bytree': 0.8, 'gamma': 0.04097848114169091, 'reg_lambda': 0.0005223913804442212, 'reg_alpha': 0.01542359630454677}. Best is trial 27 with value: 0.994137699249108.\n",
      "[I 2024-01-29 00:59:54,854] Trial 34 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-01-29 01:01:12,140] Trial 35 pruned. Trial was pruned at iteration 7.\n",
      "[I 2024-01-29 01:02:44,491] Trial 36 finished with value: 0.9601840191000742 and parameters: {'drop_subset': 2, 'state_encoders': 'none', 'purpose_encoders': 'woe', 'sigma': 1.8603801981889765, 'regularization': 2.9752827363788787, 'randomized': False, 'risk_encoders': 'target', 'scale_pos_weight': 10, 'max_depth': 15, 'min_child_weight': 9, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.8, 'gamma': 0.0077839131412574475, 'reg_lambda': 0.0010219271167134008, 'reg_alpha': 0.0003303818162636088}. Best is trial 27 with value: 0.994137699249108.\n",
      "[I 2024-01-29 01:03:34,153] Trial 37 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-01-29 01:04:58,636] Trial 38 pruned. Trial was pruned at iteration 7.\n",
      "[I 2024-01-29 01:06:05,015] Trial 39 pruned. Trial was pruned at iteration 7.\n",
      "[I 2024-01-29 01:08:19,460] Trial 40 finished with value: 0.9905766832944987 and parameters: {'drop_subset': 1, 'state_encoders': 'woe', 'sigma': 3.2859490390406605, 'regularization': 1.600398389482141, 'randomized': False, 'purpose_encoders': 'target', 'risk_encoders': 'target', 'scale_pos_weight': 20, 'max_depth': 13, 'min_child_weight': 7, 'subsample': 0.2, 'colsample_bytree': 0.7, 'gamma': 0.6960202808707747, 'reg_lambda': 0.0019125601927403677, 'reg_alpha': 0.007923069037263948}. Best is trial 27 with value: 0.994137699249108.\n",
      "[I 2024-01-29 01:09:42,418] Trial 41 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-01-29 01:11:06,808] Trial 42 finished with value: 0.9939058573345207 and parameters: {'drop_subset': 3, 'state_encoders': 'none', 'purpose_encoders': 'none', 'risk_encoders': 'target', 'scale_pos_weight': 20, 'max_depth': 15, 'min_child_weight': 8, 'subsample': 0.4, 'colsample_bytree': 0.7, 'gamma': 0.0009845791170122018, 'reg_lambda': 0.00010360973395258091, 'reg_alpha': 0.021371127893695774}. Best is trial 27 with value: 0.994137699249108.\n",
      "[I 2024-01-29 01:12:23,735] Trial 43 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-01-29 01:13:40,407] Trial 44 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-01-29 01:14:53,667] Trial 45 finished with value: 0.994041408125143 and parameters: {'drop_subset': 2, 'state_encoders': 'none', 'purpose_encoders': 'none', 'risk_encoders': 'woe', 'sigma': 2.7740596807213036, 'regularization': 3.0370958283233644, 'randomized': False, 'scale_pos_weight': 20, 'max_depth': 15, 'min_child_weight': 9, 'subsample': 0.5, 'colsample_bytree': 0.7, 'gamma': 0.003731617549133466, 'reg_lambda': 0.00018179450427802414, 'reg_alpha': 0.004688358431937551}. Best is trial 27 with value: 0.994137699249108.\n",
      "[I 2024-01-29 01:16:17,091] Trial 46 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-01-29 01:18:14,361] Trial 47 finished with value: 0.9891467596947652 and parameters: {'drop_subset': 1, 'state_encoders': 'none', 'purpose_encoders': 'target', 'risk_encoders': 'woe', 'sigma': 3.4166385569753857, 'regularization': 2.9082041353208967, 'randomized': False, 'scale_pos_weight': 10, 'max_depth': 13, 'min_child_weight': 9, 'subsample': 0.5, 'colsample_bytree': 0.7, 'gamma': 0.00022727519503710646, 'reg_lambda': 0.0001889808592286799, 'reg_alpha': 0.0012733281737963553}. Best is trial 27 with value: 0.994137699249108.\n",
      "[I 2024-01-29 01:19:18,375] Trial 48 finished with value: 0.9943489081755761 and parameters: {'drop_subset': 2, 'state_encoders': 'none', 'purpose_encoders': 'none', 'risk_encoders': 'woe', 'sigma': 2.9733922678003983, 'regularization': 4.504176873884819, 'randomized': False, 'scale_pos_weight': 20, 'max_depth': 11, 'min_child_weight': 9, 'subsample': 0.5, 'colsample_bytree': 0.9, 'gamma': 0.005328732955341684, 'reg_lambda': 0.013217689432774599, 'reg_alpha': 0.00017504294389895505}. Best is trial 48 with value: 0.9943489081755761.\n",
      "[I 2024-01-29 01:20:30,316] Trial 49 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-01-29 01:23:19,659] Trial 50 finished with value: 0.9888970776499026 and parameters: {'drop_subset': 2, 'state_encoders': 'none', 'purpose_encoders': 'none', 'risk_encoders': 'woe', 'sigma': 2.83307078443358, 'regularization': 4.427977120968727, 'randomized': False, 'scale_pos_weight': 20, 'max_depth': 11, 'min_child_weight': 9, 'subsample': 0.7, 'colsample_bytree': 1.0, 'gamma': 0.05480400648712995, 'reg_lambda': 0.009341736201447931, 'reg_alpha': 0.00019769967846426875}. Best is trial 48 with value: 0.9943489081755761.\n",
      "[I 2024-01-29 01:24:26,813] Trial 51 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-01-29 01:25:34,004] Trial 52 finished with value: 0.9941434559621452 and parameters: {'drop_subset': 2, 'state_encoders': 'none', 'purpose_encoders': 'none', 'risk_encoders': 'woe', 'sigma': 3.014171678045755, 'regularization': 3.2335382849367673, 'randomized': False, 'scale_pos_weight': 20, 'max_depth': 13, 'min_child_weight': 9, 'subsample': 0.5, 'colsample_bytree': 0.7, 'gamma': 0.004377531207324726, 'reg_lambda': 0.12912664413510552, 'reg_alpha': 0.0005948477142423302}. Best is trial 48 with value: 0.9943489081755761.\n",
      "[I 2024-01-29 01:26:57,745] Trial 53 finished with value: 0.990859138743835 and parameters: {'drop_subset': 1, 'state_encoders': 'none', 'purpose_encoders': 'none', 'risk_encoders': 'woe', 'sigma': 3.043821234996022, 'regularization': 3.279240267085325, 'randomized': False, 'scale_pos_weight': 20, 'max_depth': 11, 'min_child_weight': 9, 'subsample': 0.6000000000000001, 'colsample_bytree': 0.7, 'gamma': 0.0021587373776005463, 'reg_lambda': 0.3186848502149605, 'reg_alpha': 0.0006047311098819382}. Best is trial 48 with value: 0.9943489081755761.\n",
      "[I 2024-01-29 01:27:43,633] Trial 54 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-01-29 01:28:50,652] Trial 55 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-01-29 01:30:08,704] Trial 56 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-01-29 01:31:09,238] Trial 57 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-01-29 01:32:14,751] Trial 58 finished with value: 0.9624366862204096 and parameters: {'drop_subset': 2, 'state_encoders': 'none', 'purpose_encoders': 'none', 'risk_encoders': 'woe', 'sigma': 2.711423491786045, 'regularization': 3.1787678910940276, 'randomized': False, 'scale_pos_weight': 10, 'max_depth': 13, 'min_child_weight': 5, 'subsample': 0.6000000000000001, 'colsample_bytree': 0.7, 'gamma': 0.002692100541425249, 'reg_lambda': 0.004595153959967496, 'reg_alpha': 1.0905283836431445}. Best is trial 48 with value: 0.9943489081755761.\n",
      "[I 2024-01-29 01:33:10,671] Trial 59 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-01-29 01:34:40,596] Trial 60 finished with value: 0.989592101840984 and parameters: {'drop_subset': 1, 'state_encoders': 'none', 'purpose_encoders': 'target', 'risk_encoders': 'woe', 'sigma': 1.7243230840562465, 'regularization': 3.469877853795341, 'randomized': False, 'scale_pos_weight': 20, 'max_depth': 9, 'min_child_weight': 6, 'subsample': 0.5, 'colsample_bytree': 0.8, 'gamma': 0.01125657118508887, 'reg_lambda': 0.7022230735738787, 'reg_alpha': 0.0027305281549719887}. Best is trial 48 with value: 0.9943489081755761.\n",
      "[I 2024-01-29 01:35:56,960] Trial 61 finished with value: 0.994050892461761 and parameters: {'drop_subset': 3, 'state_encoders': 'none', 'purpose_encoders': 'woe', 'sigma': 2.0110847651548194, 'regularization': 2.698214775092308, 'randomized': False, 'risk_encoders': 'woe', 'scale_pos_weight': 20, 'max_depth': 15, 'min_child_weight': 10, 'subsample': 0.4, 'colsample_bytree': 0.7, 'gamma': 0.004353204619355858, 'reg_lambda': 0.00016495021034525968, 'reg_alpha': 0.004662901413488882}. Best is trial 48 with value: 0.9943489081755761.\n",
      "[I 2024-01-29 01:37:19,932] Trial 62 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-01-29 01:38:37,101] Trial 63 finished with value: 0.9940941419677062 and parameters: {'drop_subset': 3, 'state_encoders': 'none', 'purpose_encoders': 'woe', 'sigma': 2.044623226996883, 'regularization': 2.2921570953671506, 'randomized': False, 'risk_encoders': 'woe', 'scale_pos_weight': 20, 'max_depth': 15, 'min_child_weight': 10, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.7, 'gamma': 0.018088482881615887, 'reg_lambda': 0.009730195088370884, 'reg_alpha': 0.005311432777079238}. Best is trial 48 with value: 0.9943489081755761.\n",
      "[I 2024-01-29 01:39:53,246] Trial 64 finished with value: 0.9940941419677062 and parameters: {'drop_subset': 3, 'state_encoders': 'none', 'purpose_encoders': 'woe', 'sigma': 2.116287502936572, 'regularization': 2.2530221345636248, 'randomized': False, 'risk_encoders': 'woe', 'scale_pos_weight': 20, 'max_depth': 15, 'min_child_weight': 10, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.7, 'gamma': 0.018190864724748373, 'reg_lambda': 0.011690216264593278, 'reg_alpha': 0.005330484839026693}. Best is trial 48 with value: 0.9943489081755761.\n",
      "[I 2024-01-29 01:41:03,735] Trial 65 finished with value: 0.9941307569939937 and parameters: {'drop_subset': 3, 'state_encoders': 'none', 'purpose_encoders': 'woe', 'sigma': 1.687671398409059, 'regularization': 2.0871473336098125, 'randomized': False, 'risk_encoders': 'woe', 'scale_pos_weight': 20, 'max_depth': 13, 'min_child_weight': 10, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.6, 'gamma': 0.017082411304787902, 'reg_lambda': 0.007981319073135986, 'reg_alpha': 0.0020012187605095858}. Best is trial 48 with value: 0.9943489081755761.\n",
      "[I 2024-01-29 01:42:07,110] Trial 66 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-01-29 01:43:31,157] Trial 67 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-01-29 01:44:34,888] Trial 68 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-01-29 01:45:44,905] Trial 69 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-01-29 01:46:10,203] Trial 70 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-01-29 01:47:06,829] Trial 71 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-01-29 01:48:22,208] Trial 72 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-01-29 01:49:46,814] Trial 73 finished with value: 0.9941167812654068 and parameters: {'drop_subset': 2, 'state_encoders': 'none', 'purpose_encoders': 'woe', 'sigma': 2.442195918270612, 'regularization': 2.5036926491950635, 'randomized': False, 'risk_encoders': 'woe', 'scale_pos_weight': 20, 'max_depth': 15, 'min_child_weight': 9, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.7, 'gamma': 0.053776985005100995, 'reg_lambda': 0.003131825724459991, 'reg_alpha': 0.0052481679958173355}. Best is trial 48 with value: 0.9943489081755761.\n",
      "[I 2024-01-29 01:51:07,452] Trial 74 finished with value: 0.9945126042005958 and parameters: {'drop_subset': 2, 'state_encoders': 'none', 'purpose_encoders': 'woe', 'sigma': 2.4452363975811644, 'regularization': 2.5042270753252636, 'randomized': False, 'risk_encoders': 'woe', 'scale_pos_weight': 20, 'max_depth': 13, 'min_child_weight': 9, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.8, 'gamma': 0.14437331372653028, 'reg_lambda': 0.0025770871974866976, 'reg_alpha': 0.01706433230460041}. Best is trial 74 with value: 0.9945126042005958.\n",
      "[I 2024-01-29 01:52:28,221] Trial 75 finished with value: 0.9940169107353352 and parameters: {'drop_subset': 2, 'state_encoders': 'none', 'purpose_encoders': 'woe', 'sigma': 2.4377283440585225, 'regularization': 2.5163416498900064, 'randomized': False, 'risk_encoders': 'woe', 'scale_pos_weight': 20, 'max_depth': 13, 'min_child_weight': 9, 'subsample': 0.2, 'colsample_bytree': 0.7, 'gamma': 0.1334055057338186, 'reg_lambda': 0.003085824542246492, 'reg_alpha': 0.016899699178184638}. Best is trial 74 with value: 0.9945126042005958.\n",
      "[I 2024-01-29 01:53:51,885] Trial 76 finished with value: 0.9941800367691911 and parameters: {'drop_subset': 2, 'state_encoders': 'none', 'purpose_encoders': 'woe', 'sigma': 2.5950404045975586, 'regularization': 1.9530185140903098, 'randomized': False, 'risk_encoders': 'woe', 'scale_pos_weight': 20, 'max_depth': 15, 'min_child_weight': 9, 'subsample': 0.30000000000000004, 'colsample_bytree': 0.8, 'gamma': 0.06093463857760625, 'reg_lambda': 0.0014719858654263119, 'reg_alpha': 0.0007856506302617215}. Best is trial 74 with value: 0.9945126042005958.\n",
      "[I 2024-01-29 01:55:10,896] Trial 77 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-01-29 01:56:47,820] Trial 78 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-01-29 01:58:08,804] Trial 79 finished with value: 0.994241548179101 and parameters: {'drop_subset': 2, 'state_encoders': 'none', 'purpose_encoders': 'woe', 'sigma': 1.8387344881882761, 'regularization': 2.3465016917295367, 'randomized': False, 'risk_encoders': 'woe', 'scale_pos_weight': 20, 'max_depth': 13, 'min_child_weight': 9, 'subsample': 0.2, 'colsample_bytree': 0.9, 'gamma': 0.16303950289100064, 'reg_lambda': 0.005465217395713278, 'reg_alpha': 0.03869192792292557}. Best is trial 74 with value: 0.9945126042005958.\n",
      "[I 2024-01-29 01:59:24,953] Trial 80 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-01-29 02:00:45,895] Trial 81 finished with value: 0.994241548179101 and parameters: {'drop_subset': 2, 'state_encoders': 'none', 'purpose_encoders': 'woe', 'sigma': 1.8088736021079712, 'regularization': 2.395815846597742, 'randomized': False, 'risk_encoders': 'woe', 'scale_pos_weight': 20, 'max_depth': 13, 'min_child_weight': 9, 'subsample': 0.2, 'colsample_bytree': 0.9, 'gamma': 0.16837127399787805, 'reg_lambda': 0.0027419145700640166, 'reg_alpha': 0.03435610572100586}. Best is trial 74 with value: 0.9945126042005958.\n",
      "[I 2024-01-29 02:02:05,930] Trial 82 finished with value: 0.994241548179101 and parameters: {'drop_subset': 2, 'state_encoders': 'none', 'purpose_encoders': 'woe', 'sigma': 1.742210401813293, 'regularization': 2.5052085755996116, 'randomized': False, 'risk_encoders': 'woe', 'scale_pos_weight': 20, 'max_depth': 13, 'min_child_weight': 9, 'subsample': 0.2, 'colsample_bytree': 0.9, 'gamma': 0.1972865665076389, 'reg_lambda': 0.002515913898313702, 'reg_alpha': 0.042699316579899095}. Best is trial 74 with value: 0.9945126042005958.\n",
      "[I 2024-01-29 02:03:34,053] Trial 83 pruned. Trial was pruned at iteration 8.\n",
      "[I 2024-01-29 02:04:54,113] Trial 84 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-01-29 02:06:15,268] Trial 85 finished with value: 0.9941950840416224 and parameters: {'drop_subset': 2, 'state_encoders': 'none', 'purpose_encoders': 'woe', 'sigma': 1.2205776555633634, 'regularization': 2.8525472904051195, 'randomized': False, 'risk_encoders': 'woe', 'scale_pos_weight': 20, 'max_depth': 13, 'min_child_weight': 8, 'subsample': 0.2, 'colsample_bytree': 0.9, 'gamma': 0.11690255598296112, 'reg_lambda': 0.0008645530111436933, 'reg_alpha': 0.08563735112381635}. Best is trial 74 with value: 0.9945126042005958.\n",
      "[I 2024-01-29 02:07:55,320] Trial 86 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-01-29 02:09:12,732] Trial 87 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-01-29 02:10:43,392] Trial 88 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-01-29 02:11:39,578] Trial 89 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-01-29 02:12:54,580] Trial 90 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-01-29 02:14:14,334] Trial 91 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-01-29 02:15:34,085] Trial 92 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-01-29 02:16:48,233] Trial 93 finished with value: 0.992800487070657 and parameters: {'drop_subset': 2, 'state_encoders': 'none', 'purpose_encoders': 'woe', 'sigma': 1.814805216458743, 'regularization': 3.837857084506958, 'randomized': False, 'risk_encoders': 'woe', 'scale_pos_weight': 20, 'max_depth': 13, 'min_child_weight': 9, 'subsample': 0.2, 'colsample_bytree': 1.0, 'gamma': 0.5369282482505425, 'reg_lambda': 0.006999464335047159, 'reg_alpha': 0.0222946564133428}. Best is trial 74 with value: 0.9945126042005958.\n",
      "[I 2024-01-29 02:18:06,675] Trial 94 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-01-29 02:19:25,995] Trial 95 finished with value: 0.994386138752777 and parameters: {'drop_subset': 2, 'state_encoders': 'none', 'purpose_encoders': 'woe', 'sigma': 1.2400603342464476, 'regularization': 2.1144498177545525, 'randomized': False, 'risk_encoders': 'woe', 'scale_pos_weight': 20, 'max_depth': 11, 'min_child_weight': 8, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0.038774962841220104, 'reg_lambda': 0.002001739921755058, 'reg_alpha': 0.19665953576767392}. Best is trial 74 with value: 0.9945126042005958.\n",
      "[I 2024-01-29 02:20:42,632] Trial 96 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-01-29 02:22:06,377] Trial 97 finished with value: 0.9895939371532163 and parameters: {'drop_subset': 1, 'state_encoders': 'none', 'purpose_encoders': 'woe', 'sigma': 0.3988499276669566, 'regularization': 2.8374590822857635, 'randomized': False, 'risk_encoders': 'woe', 'scale_pos_weight': 20, 'max_depth': 9, 'min_child_weight': 8, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0.04471552204628235, 'reg_lambda': 0.0010013094095390784, 'reg_alpha': 0.06886993313517795}. Best is trial 74 with value: 0.9945126042005958.\n",
      "[I 2024-01-29 02:23:20,817] Trial 98 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-01-29 02:24:41,089] Trial 99 pruned. Trial was pruned at iteration 6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best balanced accuracy value: 0.9945126042005958\n",
      "Best ROC AUC value: 0.9994148526779225\n",
      "Best parameters:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'drop_subset': 2,\n",
       " 'state_encoders': 'none',\n",
       " 'purpose_encoders': 'woe',\n",
       " 'sigma': 2.4452363975811644,\n",
       " 'regularization': 2.5042270753252636,\n",
       " 'randomized': False,\n",
       " 'risk_encoders': 'woe',\n",
       " 'scale_pos_weight': 20,\n",
       " 'max_depth': 13,\n",
       " 'min_child_weight': 9,\n",
       " 'subsample': 0.30000000000000004,\n",
       " 'colsample_bytree': 0.8,\n",
       " 'gamma': 0.14437331372653028,\n",
       " 'reg_lambda': 0.0025770871974866976,\n",
       " 'reg_alpha': 0.01706433230460041}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def objective(trial: Trial) -> float:\n",
    "    model = instantiate_model(trial)\n",
    "    prepro = model[:-1].fit(X_train, y_train)\n",
    "    X_val_prepro = prepro.transform(X_val)\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        estimator__eval_set=[(X_val_prepro, y_val)],\n",
    "        estimator__verbose=False,\n",
    "    )\n",
    "    trial.set_user_attr(\"n_estimators\", model[-1].best_iteration + 1)\n",
    "    trial.set_user_attr(\"roc_auc\", model[-1].best_score)\n",
    "    y_pred = model.predict(X_val)\n",
    "    balanced_accuracy = balanced_accuracy_score(y_val, y_pred)\n",
    "    return balanced_accuracy\n",
    "\n",
    "\n",
    "pruner = optuna.pruners.MedianPruner(n_warmup_steps=5, n_min_trials=3)\n",
    "study = optuna.create_study(\n",
    "    study_name=\"acceptance_model_hypertune\",\n",
    "    storage=\"sqlite:///acceptance_model_hypertune.db\",\n",
    "    load_if_exists=True,\n",
    "    pruner=pruner,\n",
    "    direction=\"maximize\",\n",
    ")\n",
    "study.optimize(objective, n_trials=100)\n",
    "best_trial = study.best_trial\n",
    "n_estimators = best_trial.user_attrs[\"n_estimators\"]\n",
    "print(\"Best balanced accuracy value:\", study.best_value)\n",
    "print(\"Best ROC AUC value:\", best_trial.user_attrs[\"roc_auc\"])\n",
    "print(\"Best parameters:\")\n",
    "display(study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final tuned model obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;drop&#x27;, FeatureDropper(drop_features=[&#x27;state&#x27;])),\n",
       "                (&#x27;processor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;state&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;encoder&#x27;,\n",
       "                                                                   None)]),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002B02803AB50&gt;),\n",
       "                                                 (&#x27;purpose&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;encoder&#x27;,\n",
       "                                                                   WOEEncoder(regularization=2.5042270753252636,\n",
       "                                                                              sig...\n",
       "                               feature_types=None, gamma=0.14437331372653028,\n",
       "                               grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=None,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=10, max_delta_step=None,\n",
       "                               max_depth=13, max_leaves=None,\n",
       "                               min_child_weight=9, missing=nan,\n",
       "                               monotone_constraints=None, multi_strategy=None,\n",
       "                               n_estimators=1, n_jobs=4, num_parallel_tree=None,\n",
       "                               random_state=42, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;drop&#x27;, FeatureDropper(drop_features=[&#x27;state&#x27;])),\n",
       "                (&#x27;processor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;state&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;encoder&#x27;,\n",
       "                                                                   None)]),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002B02803AB50&gt;),\n",
       "                                                 (&#x27;purpose&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;encoder&#x27;,\n",
       "                                                                   WOEEncoder(regularization=2.5042270753252636,\n",
       "                                                                              sig...\n",
       "                               feature_types=None, gamma=0.14437331372653028,\n",
       "                               grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=None,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=10, max_delta_step=None,\n",
       "                               max_depth=13, max_leaves=None,\n",
       "                               min_child_weight=9, missing=nan,\n",
       "                               monotone_constraints=None, multi_strategy=None,\n",
       "                               n_estimators=1, n_jobs=4, num_parallel_tree=None,\n",
       "                               random_state=42, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FeatureDropper</label><div class=\"sk-toggleable__content\"><pre>FeatureDropper(drop_features=[&#x27;state&#x27;])</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">processor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;state&#x27;, Pipeline(steps=[(&#x27;encoder&#x27;, None)]),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002B02803AB50&gt;),\n",
       "                                (&#x27;purpose&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;encoder&#x27;,\n",
       "                                                  WOEEncoder(regularization=2.5042270753252636,\n",
       "                                                             sigma=2.4452363975811644))]),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002B02803B010&gt;),\n",
       "                                (&#x27;risk&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;encoder&#x27;,\n",
       "                                                  WOEEncoder(regularization=2.5042270753252636,\n",
       "                                                             sigma=2.4452363975811644))]),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002B02803BCD0&gt;)],\n",
       "                  verbose_feature_names_out=False)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">state</label><div class=\"sk-toggleable__content\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002B02803AB50&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">None</label><div class=\"sk-toggleable__content\"><pre>None</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">purpose</label><div class=\"sk-toggleable__content\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002B02803B010&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">WOEEncoder</label><div class=\"sk-toggleable__content\"><pre>WOEEncoder(regularization=2.5042270753252636, sigma=2.4452363975811644)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">risk</label><div class=\"sk-toggleable__content\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x000002B02803BCD0&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">WOEEncoder</label><div class=\"sk-toggleable__content\"><pre>WOEEncoder(regularization=2.5042270753252636, sigma=2.4452363975811644)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre></pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric=&#x27;auc&#x27;, feature_types=None,\n",
       "              gamma=0.14437331372653028, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=10, max_delta_step=None, max_depth=13,\n",
       "              max_leaves=None, min_child_weight=9, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=1,\n",
       "              n_jobs=4, num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('drop', FeatureDropper(drop_features=['state'])),\n",
       "                ('processor',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('state',\n",
       "                                                  Pipeline(steps=[('encoder',\n",
       "                                                                   None)]),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x000002B02803AB50>),\n",
       "                                                 ('purpose',\n",
       "                                                  Pipeline(steps=[('encoder',\n",
       "                                                                   WOEEncoder(regularization=2.5042270753252636,\n",
       "                                                                              sig...\n",
       "                               feature_types=None, gamma=0.14437331372653028,\n",
       "                               grow_policy='depthwise', importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=None,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=10, max_delta_step=None,\n",
       "                               max_depth=13, max_leaves=None,\n",
       "                               min_child_weight=9, missing=nan,\n",
       "                               monotone_constraints=None, multi_strategy=None,\n",
       "                               n_estimators=1, n_jobs=4, num_parallel_tree=None,\n",
       "                               random_state=42, ...))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acceptance_model = instantiate_model(best_trial)\n",
    "acceptance_model.set_params(\n",
    "    estimator__n_estimators=n_estimators,\n",
    "    estimator__early_stopping_rounds=None,\n",
    "    estimator__callbacks=None,\n",
    ")\n",
    "acceptance_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model fitted to the whole training data (training and validation sets) and dumped for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./tuned_models/acceptance_model.joblib']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pd.read_pickle(\"./data/data_train_mod1.pkl\")\n",
    "data_val = pd.read_pickle(\"./data/data_val_mod1.pkl\")\n",
    "data_train = pd.concat([data_train, data_val])\n",
    "X_train, y_train = X_y_spilt(data_train)\n",
    "acceptance_model.fit(X_train, y_train)\n",
    "joblib.dump(acceptance_model, \"./tuned_models/acceptance_model.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
