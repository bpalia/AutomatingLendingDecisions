{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lazy Prediction of Loan Acceptance Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, all the necessary libraries are imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lazypredict\n",
    "import pandas as pd\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "from helper_functions.ml_data_prep import (\n",
    "    stratified_sample,\n",
    "    X_y_spilt,\n",
    ")\n",
    "from sklearn.preprocessing import TargetEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computationally expensive and unable to execute classifiers are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = lazypredict.Supervised.CLASSIFIERS\n",
    "models_to_remove = [\n",
    "    \"StackingClassifier\",\n",
    "    \"CategoricalNB\",\n",
    "    \"LabelPropagation\",\n",
    "    \"LabelSpreading\",\n",
    "    \"KNeighborsClassifier\",\n",
    "    \"NuSVC\",\n",
    "    \"SVC\",\n",
    "    \"LinearSVC\",\n",
    "    \"RandomForestClassifier\",\n",
    "    \"ExtraTreesClassifier\",\n",
    "]\n",
    "for model, _ in classifiers[:]:\n",
    "    if model in models_to_remove:\n",
    "        classifiers.remove((model, _))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loaded and splited. Training performed only on 20% of balanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training instances 871424\n",
      "Number of validation instances 885469\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = (\n",
    "    pd.read_pickle(\"./data/data_train_balanced_mod1.pkl\")\n",
    "    .pipe(stratified_sample, frac=0.2)\n",
    "    .pipe(X_y_spilt)\n",
    ")\n",
    "X_val, y_val = pd.read_pickle(\"./data/data_val_mod1.pkl\").pipe(X_y_spilt)\n",
    "print(f\"Number of training instances {X_train.shape[0]}\")\n",
    "print(f\"Number of validation instances {X_val.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic feature engineering performed to encode high-dimensionality features and preprocessing pipeline created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_transformer = Pipeline([(\"enc\", TargetEncoder(random_state=42))])\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", cat_transformer, [\"state\"]),\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    "    verbose_feature_names_out=False,\n",
    ").set_output(transform=\"pandas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data for training and validation are preprocessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocessor.fit_transform(X_train, y_train)\n",
    "X_val = preprocessor.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A number of different classifiers are trained and evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/19 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 18/19 [02:31<00:03,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 435712, number of negative: 435712\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003937 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 773\n",
      "[LightGBM] [Info] Number of data points in the train set: 871424, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [02:34<00:00,  8.15s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Time Taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>3.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>45.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>5.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>3.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CalibratedClassifierCV</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>15.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>45.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearDiscriminantAnalysis</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.99</td>\n",
       "      <td>2.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifier</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifierCV</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.99</td>\n",
       "      <td>2.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreeClassifier</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.99</td>\n",
       "      <td>2.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.99</td>\n",
       "      <td>6.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassiveAggressiveClassifier</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.99</td>\n",
       "      <td>2.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NearestCentroid</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyClassifier</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuadraticDiscriminantAnalysis</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
       "Model                                                                           \n",
       "GaussianNB                         0.98               0.99     0.99      0.99   \n",
       "Perceptron                         0.99               0.99     0.99      0.99   \n",
       "XGBClassifier                      1.00               0.99     0.99      1.00   \n",
       "LGBMClassifier                     1.00               0.98     0.98      1.00   \n",
       "AdaBoostClassifier                 1.00               0.98     0.98      1.00   \n",
       "LogisticRegression                 0.99               0.98     0.98      0.99   \n",
       "SGDClassifier                      0.99               0.98     0.98      0.99   \n",
       "CalibratedClassifierCV             0.99               0.98     0.98      0.99   \n",
       "BaggingClassifier                  1.00               0.98     0.98      1.00   \n",
       "LinearDiscriminantAnalysis         0.99               0.97     0.97      0.99   \n",
       "RidgeClassifier                    0.99               0.97     0.97      0.99   \n",
       "RidgeClassifierCV                  0.99               0.97     0.97      0.99   \n",
       "BernoulliNB                        0.99               0.97     0.97      0.99   \n",
       "ExtraTreeClassifier                0.99               0.97     0.97      0.99   \n",
       "DecisionTreeClassifier             0.99               0.96     0.96      0.99   \n",
       "PassiveAggressiveClassifier        0.99               0.95     0.95      0.99   \n",
       "NearestCentroid                    0.64               0.75     0.75      0.75   \n",
       "DummyClassifier                    0.95               0.50     0.50      0.93   \n",
       "QuadraticDiscriminantAnalysis      0.05               0.50     0.50      0.00   \n",
       "\n",
       "                               Time Taken  \n",
       "Model                                      \n",
       "GaussianNB                           1.92  \n",
       "Perceptron                           3.03  \n",
       "XGBClassifier                        5.11  \n",
       "LGBMClassifier                       3.51  \n",
       "AdaBoostClassifier                  45.59  \n",
       "LogisticRegression                   5.03  \n",
       "SGDClassifier                        3.19  \n",
       "CalibratedClassifierCV              15.96  \n",
       "BaggingClassifier                   45.38  \n",
       "LinearDiscriminantAnalysis           2.64  \n",
       "RidgeClassifier                      1.81  \n",
       "RidgeClassifierCV                    2.48  \n",
       "BernoulliNB                          1.85  \n",
       "ExtraTreeClassifier                  2.30  \n",
       "DecisionTreeClassifier               6.76  \n",
       "PassiveAggressiveClassifier          2.80  \n",
       "NearestCentroid                      1.77  \n",
       "DummyClassifier                      1.50  \n",
       "QuadraticDiscriminantAnalysis        2.23  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LazyClassifier(random_state=42, ignore_warnings=False)\n",
    "models, predictions = clf.fit(X_train, X_val, y_train, y_val)\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though LGBMClassifier is faster than XGBClassifier, their overall performance is comparable. Since XGBClassifier could be a bit more robust because of level-wise growth compared to LGBMClassifier's leaf-wise growth, XGBClassifier is chosen to be tuned. However, it is clear that this classification is rather a trivial task. The aim is to improve predictions which could be obtained with simple heuristics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
